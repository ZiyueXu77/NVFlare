{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32460217",
   "metadata": {},
   "source": [
    "# Scikit-Learn SVM with NVFLARE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484dc228",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778adc0",
   "metadata": {},
   "source": [
    "In this section, we will download the data and split the data and save to the local disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e1229",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ede61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prepare_data import download_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5fc328",
   "metadata": {},
   "source": [
    "The download data function will download one of the two datasets from Scikit-learn: Iris or Cancer\n",
    "* the file will be save to the output directory \n",
    "* the file format will be CSV format with comma separated\n",
    "* the file will be remove the header \n",
    "* default dataset is iris\n",
    "* filename = dataset name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e95bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"/tmp/nvflare/sklearn/data\"\n",
    "download_data(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b4371",
   "metadata": {},
   "source": [
    "Verify the file is downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b116cdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e707faf5",
   "metadata": {},
   "source": [
    "#### Split Data\n",
    "* **Split Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1439e",
   "metadata": {},
   "source": [
    "\n",
    "Split the data into different datasets, one for each client. \n",
    "There are several split methods, we use test our algorithms in different scenarios. Here we just pick uniform split from the followns\n",
    "* Uniform \n",
    "* linear\n",
    "* Sqare\n",
    "* Exponential\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3179444",
   "metadata": {},
   "source": [
    "* **data store method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11134e2",
   "metadata": {},
   "source": [
    "There are two approaches to store the splited data \n",
    "* STORE DATA: \n",
    "\n",
    "similar to the real application, we split the data total into different directories (sites), and each client will ready one-site's data\n",
    "\n",
    "* STORE_INDEX: \n",
    "\n",
    "simulate the split, by assign data index range for each site, but the original file is not splited. The data loader is reading from the original file but only for the data within the index range\n",
    "  For example: the index assignment for the data split is captured in a json file\n",
    " ``` \n",
    "  {\n",
    "     \"data_path\" : \"/tmp/nvflare/sklearn/data/iris.csv\"\n",
    "     \"data_index\" : {\n",
    "         \"site-1\": {\"start\": 100, \"end\": 300},\n",
    "         \"site-2\": {\"start\": 301, \"end\": 600},\n",
    "     }\n",
    "  }\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa6c7b",
   "metadata": {},
   "source": [
    "Here we choose STORE_DATA approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9411999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prepare_data_split import split_data, SplitMethod, StoreMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aad0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/tmp/nvflare/sklearn/data/iris.csv\"\n",
    "output_dir = \"/tmp/nvflare/sklearn/data\"\n",
    "site_num = 2\n",
    "valid_frac = 0.3\n",
    "split_method: SplitMethod = SplitMethod.UNIFORM\n",
    "store_method: StoreMethod = StoreMethod.STORE_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3b7386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assign_data_index_to_sites\n",
      "valid size type <class 'int'>\n",
      "site_sizes type <class 'list'>\n",
      "start type= <class 'int'>\n",
      "end type= <class 'int'>\n",
      "start type= <class 'int'>\n",
      "end type= <class 'int'>\n",
      "{'valid': {'start': 0, 'end': 45}, 'site-1': {'start': 45, 'end': 97}, 'site-2': {'start': 97, 'end': 150}}\n",
      "output_file= /tmp/nvflare/sklearn/data/data_valid.csv\n",
      "['0.0,5.1,3.5,1.4,0.2\\n', '0.0,4.9,3.0,1.4,0.2\\n', '0.0,4.7,3.2,1.3,0.2\\n', '0.0,4.6,3.1,1.5,0.2\\n', '0.0,5.0,3.6,1.4,0.2\\n', '0.0,5.4,3.9,1.7,0.4\\n', '0.0,4.6,3.4,1.4,0.3\\n', '0.0,5.0,3.4,1.5,0.2\\n', '0.0,4.4,2.9,1.4,0.2\\n', '0.0,4.9,3.1,1.5,0.1\\n', '0.0,5.4,3.7,1.5,0.2\\n', '0.0,4.8,3.4,1.6,0.2\\n', '0.0,4.8,3.0,1.4,0.1\\n', '0.0,4.3,3.0,1.1,0.1\\n', '0.0,5.8,4.0,1.2,0.2\\n', '0.0,5.7,4.4,1.5,0.4\\n', '0.0,5.4,3.9,1.3,0.4\\n', '0.0,5.1,3.5,1.4,0.3\\n', '0.0,5.7,3.8,1.7,0.3\\n', '0.0,5.1,3.8,1.5,0.3\\n', '0.0,5.4,3.4,1.7,0.2\\n', '0.0,5.1,3.7,1.5,0.4\\n', '0.0,4.6,3.6,1.0,0.2\\n', '0.0,5.1,3.3,1.7,0.5\\n', '0.0,4.8,3.4,1.9,0.2\\n', '0.0,5.0,3.0,1.6,0.2\\n', '0.0,5.0,3.4,1.6,0.4\\n', '0.0,5.2,3.5,1.5,0.2\\n', '0.0,5.2,3.4,1.4,0.2\\n', '0.0,4.7,3.2,1.6,0.2\\n', '0.0,4.8,3.1,1.6,0.2\\n', '0.0,5.4,3.4,1.5,0.4\\n', '0.0,5.2,4.1,1.5,0.1\\n', '0.0,5.5,4.2,1.4,0.2\\n', '0.0,4.9,3.1,1.5,0.2\\n', '0.0,5.0,3.2,1.2,0.2\\n', '0.0,5.5,3.5,1.3,0.2\\n', '0.0,4.9,3.6,1.4,0.1\\n', '0.0,4.4,3.0,1.3,0.2\\n', '0.0,5.1,3.4,1.5,0.2\\n', '0.0,5.0,3.5,1.3,0.3\\n', '0.0,4.5,2.3,1.3,0.3\\n', '0.0,4.4,3.2,1.3,0.2\\n', '0.0,5.0,3.5,1.6,0.6\\n', '0.0,5.1,3.8,1.9,0.4\\n']\n",
      "output_file= /tmp/nvflare/sklearn/data/data_site-1.csv\n",
      "['0.0,4.8,3.0,1.4,0.3\\n', '0.0,5.1,3.8,1.6,0.2\\n', '0.0,4.6,3.2,1.4,0.2\\n', '0.0,5.3,3.7,1.5,0.2\\n', '0.0,5.0,3.3,1.4,0.2\\n', '1.0,7.0,3.2,4.7,1.4\\n', '1.0,6.4,3.2,4.5,1.5\\n', '1.0,6.9,3.1,4.9,1.5\\n', '1.0,5.5,2.3,4.0,1.3\\n', '1.0,6.5,2.8,4.6,1.5\\n', '1.0,5.7,2.8,4.5,1.3\\n', '1.0,6.3,3.3,4.7,1.6\\n', '1.0,4.9,2.4,3.3,1.0\\n', '1.0,6.6,2.9,4.6,1.3\\n', '1.0,5.2,2.7,3.9,1.4\\n', '1.0,5.0,2.0,3.5,1.0\\n', '1.0,5.9,3.0,4.2,1.5\\n', '1.0,6.0,2.2,4.0,1.0\\n', '1.0,6.1,2.9,4.7,1.4\\n', '1.0,5.6,2.9,3.6,1.3\\n', '1.0,6.7,3.1,4.4,1.4\\n', '1.0,5.6,3.0,4.5,1.5\\n', '1.0,5.8,2.7,4.1,1.0\\n', '1.0,6.2,2.2,4.5,1.5\\n', '1.0,5.6,2.5,3.9,1.1\\n', '1.0,5.9,3.2,4.8,1.8\\n', '1.0,6.1,2.8,4.0,1.3\\n', '1.0,6.3,2.5,4.9,1.5\\n', '1.0,6.1,2.8,4.7,1.2\\n', '1.0,6.4,2.9,4.3,1.3\\n', '1.0,6.6,3.0,4.4,1.4\\n', '1.0,6.8,2.8,4.8,1.4\\n', '1.0,6.7,3.0,5.0,1.7\\n', '1.0,6.0,2.9,4.5,1.5\\n', '1.0,5.7,2.6,3.5,1.0\\n', '1.0,5.5,2.4,3.8,1.1\\n', '1.0,5.5,2.4,3.7,1.0\\n', '1.0,5.8,2.7,3.9,1.2\\n', '1.0,6.0,2.7,5.1,1.6\\n', '1.0,5.4,3.0,4.5,1.5\\n', '1.0,6.0,3.4,4.5,1.6\\n', '1.0,6.7,3.1,4.7,1.5\\n', '1.0,6.3,2.3,4.4,1.3\\n', '1.0,5.6,3.0,4.1,1.3\\n', '1.0,5.5,2.5,4.0,1.3\\n', '1.0,5.5,2.6,4.4,1.2\\n', '1.0,6.1,3.0,4.6,1.4\\n', '1.0,5.8,2.6,4.0,1.2\\n', '1.0,5.0,2.3,3.3,1.0\\n', '1.0,5.6,2.7,4.2,1.3\\n', '1.0,5.7,3.0,4.2,1.2\\n', '1.0,5.7,2.9,4.2,1.3\\n']\n",
      "output_file= /tmp/nvflare/sklearn/data/data_site-2.csv\n",
      "['1.0,6.2,2.9,4.3,1.3\\n', '1.0,5.1,2.5,3.0,1.1\\n', '1.0,5.7,2.8,4.1,1.3\\n', '2.0,6.3,3.3,6.0,2.5\\n', '2.0,5.8,2.7,5.1,1.9\\n', '2.0,7.1,3.0,5.9,2.1\\n', '2.0,6.3,2.9,5.6,1.8\\n', '2.0,6.5,3.0,5.8,2.2\\n', '2.0,7.6,3.0,6.6,2.1\\n', '2.0,4.9,2.5,4.5,1.7\\n', '2.0,7.3,2.9,6.3,1.8\\n', '2.0,6.7,2.5,5.8,1.8\\n', '2.0,7.2,3.6,6.1,2.5\\n', '2.0,6.5,3.2,5.1,2.0\\n', '2.0,6.4,2.7,5.3,1.9\\n', '2.0,6.8,3.0,5.5,2.1\\n', '2.0,5.7,2.5,5.0,2.0\\n', '2.0,5.8,2.8,5.1,2.4\\n', '2.0,6.4,3.2,5.3,2.3\\n', '2.0,6.5,3.0,5.5,1.8\\n', '2.0,7.7,3.8,6.7,2.2\\n', '2.0,7.7,2.6,6.9,2.3\\n', '2.0,6.0,2.2,5.0,1.5\\n', '2.0,6.9,3.2,5.7,2.3\\n', '2.0,5.6,2.8,4.9,2.0\\n', '2.0,7.7,2.8,6.7,2.0\\n', '2.0,6.3,2.7,4.9,1.8\\n', '2.0,6.7,3.3,5.7,2.1\\n', '2.0,7.2,3.2,6.0,1.8\\n', '2.0,6.2,2.8,4.8,1.8\\n', '2.0,6.1,3.0,4.9,1.8\\n', '2.0,6.4,2.8,5.6,2.1\\n', '2.0,7.2,3.0,5.8,1.6\\n', '2.0,7.4,2.8,6.1,1.9\\n', '2.0,7.9,3.8,6.4,2.0\\n', '2.0,6.4,2.8,5.6,2.2\\n', '2.0,6.3,2.8,5.1,1.5\\n', '2.0,6.1,2.6,5.6,1.4\\n', '2.0,7.7,3.0,6.1,2.3\\n', '2.0,6.3,3.4,5.6,2.4\\n', '2.0,6.4,3.1,5.5,1.8\\n', '2.0,6.0,3.0,4.8,1.8\\n', '2.0,6.9,3.1,5.4,2.1\\n', '2.0,6.7,3.1,5.6,2.4\\n', '2.0,6.9,3.1,5.1,2.3\\n', '2.0,5.8,2.7,5.1,1.9\\n', '2.0,6.8,3.2,5.9,2.3\\n', '2.0,6.7,3.3,5.7,2.5\\n', '2.0,6.7,3.0,5.2,2.3\\n', '2.0,6.3,2.5,5.0,1.9\\n', '2.0,6.5,3.0,5.2,2.0\\n', '2.0,6.2,3.4,5.4,2.3\\n', '2.0,5.9,3.0,5.1,1.8\\n']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_data(input_path, output_dir, site_num, valid_frac, split_method=split_method, store_method=store_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073c1180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "-rw-r--r--  1 chesterc  wheel  1040 Dec 16 09:32 data_site-1.csv\r\n",
      "-rw-r--r--  1 chesterc  wheel  1060 Dec 16 09:32 data_site-2.csv\r\n",
      "-rw-r--r--  1 chesterc  wheel     0 Dec 16 09:26 data_site-3.csv\r\n",
      "-rw-r--r--  1 chesterc  wheel   900 Dec 16 09:32 data_valid.csv\r\n",
      "-rw-r--r--  1 chesterc  wheel  3000 Dec 16 09:19 iris.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b69d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
